{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.9.4", "generated_at": "2025-11-19T21:59:09.542497Z", "invocation_id": "78647ca1-b1a4-409f-abff-cf7e9db7a772", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:24.744740Z", "completed_at": "2025-11-19T21:58:24.765574Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:24.766261Z", "completed_at": "2025-11-19T21:58:28.184691Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 3.441476583480835, "adapter_response": {"_message": "SUCCESS 3", "code": "SUCCESS", "rows_affected": 3, "query_id": "01c08106-0107-1236-0032-318705ad1cc2"}, "message": "SUCCESS 3", "failures": null, "unique_id": "model.incident_management.users", "compiled": true, "compiled_code": "\n\nwith _temp as (\n select \n *, \n arrays_zip(memberids, memberemails) as zip_data \n from incident_management.bronze_zone.slack_members sm\n)\nselect \n   f.value:$1 as id,\n   f.value:$2 as email,\n    split(email, '@')[0] as first_name,\n    split(email, '@')[1] as last_name,\n    'reporter' as role,\n    '' as department,\n    '' as team,\n    true as is_active,\n    current_timestamp() as created_at,\n    current_timestamp() as updated_at\nfrom _temp,\nlateral flatten(input => zip_data) f", "relation_name": "incident_management.bronze_zone.users", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:28.192860Z", "completed_at": "2025-11-19T21:58:28.207144Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:28.207853Z", "completed_at": "2025-11-19T21:58:29.888017Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 1.6966423988342285, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c08106-0107-1236-0032-318705ad1cea"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.incident_management.v_qualify_new_documents", "compiled": true, "compiled_code": "\n\nselect\n   *,\n    case \n        when contains(relative_path, 'qa') then 'question'\n        when contains(relative_path, 'full') then 'full'\n        else 'slack'\n    end as doc_type,\n    split_part(relative_path, '.', 2) as extension\nfrom incident_management.bronze_zone.documents_stream\nWHERE METADATA$ACTION != 'DELETE'\nand relative_path is not null\nand array_contains(extension::VARIANT, ['pdf', 'docx', 'doc', 'txt', 'text', 'html', 'md', 'pptx', 'ppt', 'png', 'eml', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff', 'tif', 'webp', 'htm'] )\nand size > 0", "relation_name": "incident_management.bronze_zone.v_qualify_new_documents", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:29.894346Z", "completed_at": "2025-11-19T21:58:30.053510Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:30.054177Z", "completed_at": "2025-11-19T21:58:31.822274Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 1.9294304847717285, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c08106-0107-1236-0032-318705ad1d0a"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.incident_management.v_qualify_slack_messages", "compiled": true, "compiled_code": "\n\n-- Only propagate messages from known reporters (users in channel)\nwith slack_messages_from_known_reporters as (\n    select sm.*, r.id as reporter_id\n    from incident_management.bronze_zone.slack_messages sm\n    inner join incident_management.bronze_zone.users r on sm.username = split(r.email, '@')[0]\n    where sm.clientmsgid is not null\n    and to_date(sm.ingestts) >= to_date(current_timestamp())\n)\n\n-- Messages with attachments (with join to doc_metadata)\nselect \n    true as hasfiles,\n    sm.type,\n    sm.subtype,\n    sm.team,\n    sm.channel,\n    sm.user,\n    sm.username,\n    sm.reporter_id,\n    sm.text,\n    sm.ts,\n    sm.clientmsgid as slack_message_id,\n    \n    -- Attachment metadata from doc_metadata\n    dm.file_id,\n    dm.file_name, \n    dm.file_mimetype, \n    dm.file_size, \n    dm.staged_file_path,\n    to_file('@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS', dm.staged_file_path) as attachment_file,\n    case \n        -- When there is an attachment file and it is an image, use the image to extract the incident code\n        -- TODO: Add structured response\n        when dm.staged_file_path is not null and fl_is_image(to_file('@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS', dm.staged_file_path)) then \n        ai_complete('claude-3-5-sonnet',\n            prompt(\n            $$\n            Find the incident number that may be present either in the image {0} or in the text {1}. \n            Use the one in the image if found.Look for alphanumeric codes preceded by the keyword 'incident' (case-insensitive). \n            Examples: INC-12345, incident_001, INC-2025-001.\n            Respond only in JSON format with a single key called 'incident_code'.\n            Do not add any explanation in the response.\n            $$, \n            attachment_file,\n            text\n            )\n        )\n        else null\n    end as incident_number\n\nfrom slack_messages_from_known_reporters sm\ninner join incident_management.bronze_zone.doc_metadata dm \non (sm.hasfiles and (sm.channel = dm.channel_id) and (sm.ts = dm.event_ts))\n\nUNION ALL\n\n-- Messages without attachments (no join to doc_metadata)\nselect \n    false as hasfiles,\n    sm.type,\n    sm.subtype,\n    sm.team,\n    sm.channel,\n    sm.user,\n    sm.username,\n    sm.reporter_id,\n    sm.text,\n    sm.ts,\n    sm.clientmsgid as slack_message_id,\n    \n    -- No attachment metadata for messages without files\n    null as file_id,\n    null as file_name, \n    null as file_mimetype, \n    null as file_size, \n    null as staged_file_path,\n    null as attachment_file,\n    case \n        -- Only use text to extract the incident code since there are no attachments\n        -- TODO: Add structured response\n        when sm.text is not null then ai_complete('claude-3-5-sonnet',\n                prompt(\n                $$\n                Extract incident codes from Slack text {0}. \n                Look for alphanumeric codes preceded by the keyword 'incident' (case-insensitive). \n                Examples: INC-12345, incident_001, INC-2025-001.\n                Respond only in JSON format with a single key called 'incident_code'.\n                Do not add any explanation in the response.\n                $$, \n                text\n            )\n        )\n        else null\n    end as incident_number\n\nfrom slack_messages_from_known_reporters sm\nwhere not sm.hasfiles or sm.hasfiles is null", "relation_name": "incident_management.bronze_zone.v_qualify_slack_messages", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:31.828560Z", "completed_at": "2025-11-19T21:58:31.844110Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:31.844770Z", "completed_at": "2025-11-19T21:58:36.787899Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 4.960942268371582, "adapter_response": {"_message": "SUCCESS 0", "code": "SUCCESS", "rows_affected": 0, "query_id": "01c08106-0107-1236-0032-318705ad1d3e"}, "message": "SUCCESS 0", "failures": null, "unique_id": "model.incident_management.document_full_extracts", "compiled": true, "compiled_code": "\n\nwith \ndocuments_raw_extracts as(\n    select\n        * exclude (METADATA$ACTION, METADATA$ISUPDATE, METADATA$ROW_ID) ,\n        AI_PARSE_DOCUMENT (\n            TO_FILE('@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS',relative_path),\n             {\n                'mode': 'LAYOUT'\n                ,'page_split': True\n             }\n        ) as raw_extracts\n        FROM incident_management.bronze_zone.v_qualify_new_documents\n        WHERE lower(doc_type) = 'full'\n),\ndocuments_chunked_extracts as\n(\n    select \n    og1.* exclude (raw_extracts),\n    SNOWFLAKE.CORTEX.SPLIT_TEXT_MARKDOWN_HEADER(\n        lf1.value:content::STRING,\n        OBJECT_CONSTRUCT('#', 'header_1', '##', 'header_2'),\n        500,\n        5\n    ) as page_chunks,\n    lf1.index::int as page_num\n    from documents_raw_extracts og1,\n    LATERAL FLATTEN(input => raw_extracts:pages) lf1\n)\n\nselect \n    og2.* exclude (page_chunks), \n    lf2.value['chunk']::varchar as chunk,\n    lf2.value['headers']::object as headers\nfrom documents_chunked_extracts og2,\nlateral flatten(input => page_chunks) lf2", "relation_name": "incident_management.silver_zone.document_full_extracts", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:36.795189Z", "completed_at": "2025-11-19T21:58:36.836272Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:36.837334Z", "completed_at": "2025-11-19T21:58:44.726629Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 7.933332920074463, "adapter_response": {"_message": "SUCCESS 0", "code": "SUCCESS", "rows_affected": 0, "query_id": "01c08106-0107-1236-0032-318705ad1d92"}, "message": "SUCCESS 0", "failures": null, "unique_id": "model.incident_management.document_question_extracts", "compiled": true, "compiled_code": "import snowflake.snowpark.functions as F\nfrom snowflake.snowpark import Session\n\n    \ndef model(dbt, session: Session):\n\n    dbt.config(\n        materialized='incremental',\n        incremental_strategy='append',\n        description='Table to store question extracts from documents'\n    )\n    \n    docs_stage = dbt.config.get(\"docs_stage_path\")\n\n    all_meta = dbt.config.get(\"meta\")\n    \n    reponse_schema = {\n        'schema': {\n            'type': 'object',\n            'properties': {}\n        }\n    }\n    \n    for key in all_meta.keys():\n        if all_meta[key]['enabled']:\n            for prop in all_meta[key]['schema']['properties']:\n                reponse_schema['schema']['properties'][prop] = all_meta[key]['schema']['properties'][prop]\n\n\n    # Get the upstream model\n    v_qualify_new_documents = dbt.ref('v_qualify_new_documents')\n    \n    # Filter for question analysis type\n    document_all_pages = v_qualify_new_documents.filter(\n        F.lower(F.col('doc_type')) == 'question'\n    ).drop(\n        \"METADATA$ACTION\",\n        \"METADATA$ISUPDATE\",\n        \"METADATA$ROW_ID\"\n    )\n    \n    document_all_pages = document_all_pages.with_column(\n        'question_extracts_json',\n        F.call_builtin(\n            'AI_EXTRACT',\n            F.call_builtin('TO_FILE', F.lit(f'{docs_stage}'), F.col('relative_path')),\n            reponse_schema\n        )\n    ) \n    \n    return document_all_pages\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {\"v_qualify_new_documents\": \"incident_management.bronze_zone.v_qualify_new_documents\"}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {'docs_stage_path': '@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS', 'meta': {'quaterly_review_metrics': {'enabled': True, 'schema': {'type': 'object', 'properties': {'quarter': {'description': 'The year and quarter of the review metrics', 'type': 'string'}, 'overall_uptime': {'description': 'The actual recorded overall uptime of all services', 'type': 'string'}, 'critical_services_uptime': {'description': 'What was the actual recorded  uptime of critical services', 'type': 'string'}, 'sev_1_incidents': {'description': 'What were the actual recorded string of Sev-1 incidents', 'type': 'string'}, 'sev_2_incidents': {'description': 'What were the actual recorded string of Sev-2 incidents', 'type': 'string'}, 'mtta': {'description': 'What was the actual recorded mean time to acknowledge an incident', 'type': 'string'}, 'mttr': {'description': 'What was the actual recorded mean time to recover from an incident', 'type': 'string'}, 'change_failure_rate': {'description': 'What was the actual recorded change failure rate', 'type': 'string'}, 'slo_breaches': {'description': 'What was the actual recorded string of SLO breaches', 'type': 'string'}, 'error_budget_consumed': {'description': 'What was the actual recorded error budget consumed', 'type': 'string'}, 'service_downtime': {'description': 'What was the actual recorded service downtime', 'type': 'string'}, 'unplanned_outage_hours': {'description': 'What was the actual recorded unplanned outage hours', 'type': 'string'}, 'planned_maintenance_hours': {'description': 'What was the actual recorded planned maintenance hours', 'type': 'string'}, 'sev_1_outage_minutes': {'description': 'What was the actual recorded Sev-1 outage minutes', 'type': 'string'}, 'sev_2_outage_minutes': {'description': 'What was the actual recorded Sev-2 outage minutes', 'type': 'string'}, 'longest_single_outage': {'description': 'What was the actual recorded longest single outage', 'type': 'string'}, 'mtbft': {'description': 'What was the actual recorded mean time between failures', 'type': 'string'}, 'end_of_quarter_it_headcount': {'description': 'What was the actual recorded end of quarter IT headcount', 'type': 'string'}, 'engineering_headcount': {'description': 'What was the actual recorded engineering headcount', 'type': 'string'}, 'on_call_coverage': {'description': 'What was the actual recorded on call coverage', 'type': 'string'}, 'project_work_allocation': {'description': 'What was the actual recorded project work allocation', 'type': 'string'}, 'bau_operations_allocation': {'description': 'What was the actual recorded BAU/Operations allocation', 'type': 'string'}, 'on_call_hours_per_engineer': {'description': 'What was the actual recorded on call hours per engineer', 'type': 'string'}, 'after_hours_incidents_handled': {'description': 'What was the actual recorded after hours incidents handled', 'type': 'string'}, 'training_hours_per_fte': {'description': 'What was the actual recorded training hours per FTE', 'type': 'string'}, 'certifications_earned': {'description': 'What was the actual recorded certifications earned', 'type': 'string'}, 'attrition': {'description': 'What was the actual recorded attrition', 'type': 'string'}, 'atlassian_spend': {'description': 'What was the actual spend on Atlassian licenses', 'type': 'string'}, 'github_spend': {'description': 'What was the actual spend on GitHub licenses', 'type': 'string'}, 'slack_spend': {'description': 'What was the actual spend on Slack licenses', 'type': 'string'}, 'pagerduty_spend': {'description': 'What was the actual spend on PagerDuty licenses', 'type': 'string'}, 'datadog_spend': {'description': 'What was the actual spend on Datadog licenses', 'type': 'string'}, 'sentry_spend': {'description': 'What was the actual spend on Sentry licenses', 'type': 'string'}, 'okta_spend': {'description': 'What was the actual spend on Okta licenses', 'type': 'string'}, 'aws_spend': {'description': 'What was the actual spend on AWS licenses', 'type': 'string'}, 'total_spend': {'description': 'What was the actual spend on total licenses', 'type': 'string'}}}}}}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"incident_management\"\n    schema = \"silver_zone\"\n    identifier = \"document_question_extracts\"\n    \n    def __repr__(self):\n        return 'incident_management.silver_zone.document_question_extracts'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = True\n\n# COMMAND ----------\n\n\n", "relation_name": "incident_management.silver_zone.document_question_extracts", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:44.733551Z", "completed_at": "2025-11-19T21:58:44.747121Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:44.747794Z", "completed_at": "2025-11-19T21:58:52.741952Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 8.009832859039307, "adapter_response": {"_message": "SUCCESS 0", "code": "SUCCESS", "rows_affected": 0, "query_id": "01c08106-0107-1236-0032-318705ad1dd2"}, "message": "SUCCESS 0", "failures": null, "unique_id": "model.incident_management.incidents", "compiled": true, "compiled_code": "-- Create only new incidents in this incremental mode; new incidents are detected by absence of an incident number from previous step in the pipeline or,\n-- they are not related to any existing incident by title and text.\n\n\n-- Get recent open incidents for lookback when incident_code is null\nwith \n\nrecent_open_incidents as (\n    select * from incident_management.gold_zone.incidents\n    where lower(status) = 'open' \n    and reportee_id is not null\n    and created_at > dateadd('day', -7, current_timestamp())\n)\n\n, new_slack_messages as (\n    select \n        lh.*\n    from incident_management.bronze_zone.v_qualify_slack_messages lh \n    left join recent_open_incidents rh \n    on lh.slack_message_id = rh.slack_message_id\n    where rh.slack_message_id is null\n)\n\n-- Split messages based on whether they have valid incident codes\n, messages_with_incident_code as (\n    select \n        * exclude(incident_number),\n        parse_json(incident_number):incident_code::string as incident_number\n    from new_slack_messages\n    where not IS_NULL_VALUE(parse_json(incident_number):incident_code)\n)\n\n, messages_without_incident_code as (\n    select \n        * exclude(incident_number),\n        '' as incident_number\n    from new_slack_messages\n    where IS_NULL_VALUE(parse_json(incident_number):incident_code)\n)\n\n-- For messages without incident codes, try to find existing incidents\n, messages_with_matching_incidents as (\n    select \n        sm.*,\n        ai_classify(sm.text, ['payment gateway error', 'login error', 'other']):labels[0] as text_category,\n        roi.incident_number as existing_incident_number\n    from messages_without_incident_code sm\n    left join recent_open_incidents roi \n    on sm.channel = roi.external_source_id \n    and sm.username = roi.reportee_id \n    and ai_filter(\n     prompt('The text category {0} is logically relatable to this record\\'s category {1}', text_category, roi.category)\n    )\n)\n\n-- Combine all messages with their appropriate incident numbers\n, all_processed_messages as (\n    -- Messages that already have incident codes\n    select *, incident_number as final_incident_number\n    from messages_with_incident_code\n    \n    union\n    \n    -- Messages without incident codes, use existing if found, otherwise generate new\n    select \n        * exclude (existing_incident_number, text_category),\n        coalesce(existing_incident_number, concat_ws('-', 'INC', '2025', randstr(3, random()))) as final_incident_number\n    from messages_with_matching_incidents\n)\n\n, enriched_incidents as (\n    select\n        -- Core incident fields matching DDL schema\n        case \n            when not IS_NULL_VALUE(parse_json(sri.incident_number):incident_code) then \n                parse_json(sri.incident_number):incident_code::string\n            else sri.final_incident_number\n        end as incident_number,        \n        \n        -- Image or Text Classification\n        case \n            when sri.attachment_file is not null then \n                ai_classify(sri.attachment_file, ['payment gateway error', 'login error', 'other']):labels[0]\n            else ai_classify(sri.text, ['payment gateway error', 'login error', 'other']):labels[0]\n        end as category,\n        ai_classify(sri.text, ['payment gateway error', 'login error', 'other']):labels[0] as title, \n        case \n            when category = 'payment gateway error' then 'critical'\n            when category = 'login error' then 'high'\n            else 'low'\n        end as priority,\n        \n        -- Status tracking\n        'open' as status,\n        \n        -- People involved\n        '' as assignee_id,\n        sri.reporter_id as reportee_id,\n        \n        -- Timestamps\n        sri.ts as created_at,\n        null as closed_at,\n        sri.ts as updated_at,\n        \n        -- System fields\n        'Slack' as source_system,\n        sri.channel as external_source_id,\n        sri.hasfiles as has_attachments,\n        sri.slack_message_id,\n        \n        -- Latest comment\n        sri.text as last_comment\n\n        \n    from all_processed_messages sri\n)\n\nselect * \nfrom enriched_incidents", "relation_name": "incident_management.gold_zone.incidents", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:52.748134Z", "completed_at": "2025-11-19T21:58:52.761990Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:52.762635Z", "completed_at": "2025-11-19T21:58:55.986304Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 3.239654302597046, "adapter_response": {"_message": "SUCCESS 0", "code": "SUCCESS", "rows_affected": 0, "query_id": "01c08106-0107-1236-0032-318705ad1e0e"}, "message": "SUCCESS 0", "failures": null, "unique_id": "model.incident_management.quaterly_review_metrics", "compiled": true, "compiled_code": "\n\n\nwith document_question_extracts as (\n  select \n  split(relative_path, '/')[1] as filename,\n  QUESTION_EXTRACTS_JSON:response as response\n  from incident_management.silver_zone.document_question_extracts \n  where \n  \n    lower(trim(filename)) not in ( select distinct lower(trim(filename)) from incident_management.gold_zone.quaterly_review_metrics )\n    and to_timestamp_ntz(last_modified) > ( select max(to_timestamp_ntz(created_at)) from incident_management.gold_zone.quaterly_review_metrics )\n    and is_null_value(question_extracts_json:error)\n  \n  \n)\nselect\ndq.filename,\nlf.key as metric,\nlf.value::string as value,\ncurrent_timestamp() as created_at,\nfrom document_question_extracts dq,\nlateral flatten(input => response) lf", "relation_name": "incident_management.gold_zone.quaterly_review_metrics", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:55.992243Z", "completed_at": "2025-11-19T21:58:56.005226Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:56.005862Z", "completed_at": "2025-11-19T21:58:57.460112Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 1.4693551063537598, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c08106-0107-1236-0032-318705ad1e36"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.incident_management.active_incidents", "compiled": true, "compiled_code": "\n\nSELECT \n    i.incident_number,\n    i.title,\n    i.category,\n    i.priority,\n    i.status,\n    i.assignee_id,\n    CONCAT(assignee.first_name, ' ', assignee.last_name) AS assignee_name,\n    i.reportee_id,\n    CONCAT(reportee.first_name, ' ', reportee.last_name) AS reportee_name,\n    i.created_at,\n    i.updated_at,\n    DATEDIFF('hour', i.created_at, CURRENT_TIMESTAMP()) AS age_hours,\n    i.source_system,\n    i.external_source_id,\n    i.has_attachments\nFROM incident_management.gold_zone.incidents i\nLEFT JOIN incident_management.bronze_zone.users assignee ON i.assignee_id = assignee.id\nLEFT JOIN incident_management.bronze_zone.users reportee ON i.reportee_id = reportee.id\nWHERE i.status = 'open'", "relation_name": "incident_management.gold_zone.active_incidents", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:57.465947Z", "completed_at": "2025-11-19T21:58:57.480641Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:57.481290Z", "completed_at": "2025-11-19T21:58:59.785693Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.3211617469787598, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c08106-0107-1236-0032-318705ad1e56"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.incident_management.closed_incidents", "compiled": true, "compiled_code": "\n\nSELECT \n    i.incident_number,\n    i.title,\n    i.category,\n    i.priority,\n    i.status,\n    i.assignee_id,\n    i.reportee_id,\n    \n    -- Timeline fields (only available DDL fields)\n    i.created_at,\n    i.closed_at,\n    i.updated_at,\n    \n    -- System information\n    i.source_system,\n    i.external_source_id,\n    i.has_attachments,\n    \n    -- Resolution metrics (simplified)\n    DATEDIFF('minute', i.created_at, i.closed_at) / 60.0 AS total_resolution_hours,\n    \n    -- Month/Year for trending\n    DATE_TRUNC('month', i.closed_at) AS closed_month,\n    EXTRACT(year FROM i.closed_at) AS closed_year,\n    EXTRACT(quarter FROM i.closed_at) AS closed_quarter\n\nFROM incident_management.gold_zone.incidents i\nWHERE LOWER(i.status) IN ('closed', 'resolved') AND i.closed_at IS NOT NULL", "relation_name": "incident_management.gold_zone.closed_incidents", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:58:59.791536Z", "completed_at": "2025-11-19T21:58:59.806713Z"}, {"name": "execute", "started_at": "2025-11-19T21:58:59.807391Z", "completed_at": "2025-11-19T21:59:03.169869Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 3.379821538925171, "adapter_response": {"_message": "SUCCESS 0", "code": "SUCCESS", "rows_affected": 0, "query_id": "01c08107-0107-1236-0032-318705ad1e8a"}, "message": "SUCCESS 0", "failures": null, "unique_id": "model.incident_management.incident_attachments", "compiled": true, "compiled_code": "\n\nselect \n    dm.file_id as id,\n    i.incident_number,\n    to_file('@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS', dm.staged_file_path) as attachment_file,\n    dm.event_ts as uploaded_at\nfrom incident_management.gold_zone.incidents i\ninner join incident_management.bronze_zone.doc_metadata dm \non i.has_attachments \nand i.reportee_id = dm.user_id \nand i.external_source_id = dm.channel_id\nand i.created_at = dm.event_ts", "relation_name": "incident_management.gold_zone.incident_attachments", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:59:03.175645Z", "completed_at": "2025-11-19T21:59:03.189309Z"}, {"name": "execute", "started_at": "2025-11-19T21:59:03.190000Z", "completed_at": "2025-11-19T21:59:06.130283Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.956087112426758, "adapter_response": {"_message": "SUCCESS 0", "code": "SUCCESS", "rows_affected": 0, "query_id": "01c08107-0107-1236-0032-318705ad1eca"}, "message": "SUCCESS 0", "failures": null, "unique_id": "model.incident_management.incident_comment_history", "compiled": true, "compiled_code": "\n\nselect \n    slack_message_id as id,\n    i.incident_number,\n    i.reportee_id as author_id,\n    i.last_comment as content,\n    current_timestamp() as created_at\nfrom incident_management.gold_zone.incidents i\n\n\nwhere i.updated_at > (select coalesce(max(created_at), dateadd('day', -1, current_timestamp())) from incident_management.gold_zone.incident_comment_history)\nand i.updated_at >= dateadd('day', -1, current_timestamp())\nand i.status = 'open'\n", "relation_name": "incident_management.gold_zone.incident_comment_history", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:59:06.135775Z", "completed_at": "2025-11-19T21:59:06.148154Z"}, {"name": "execute", "started_at": "2025-11-19T21:59:06.148874Z", "completed_at": "2025-11-19T21:59:07.870292Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 1.7358925342559814, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c08107-0107-1236-0032-318705ad1ef2"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.incident_management.weekly_incident_trends", "compiled": true, "compiled_code": "\n\nSELECT \n    DATE_TRUNC('week', created_at) AS week,\n    COUNT(*) AS total_incidents,\n    COUNT(CASE WHEN status = 'resolved' THEN 1 END) AS resolved_incidents,\n    COUNT(CASE WHEN status = 'closed' THEN 1 END) AS closed_incidents,\n    COUNT(CASE WHEN status = 'open' THEN 1 END) AS open_incidents,\n    COUNT(CASE WHEN priority = 'critical' THEN 1 END) AS critical_incidents,\n    COUNT(CASE WHEN priority = 'high' THEN 1 END) AS high_incidents,\n    COUNT(CASE WHEN priority IN ('critical', 'high') THEN 1 END) AS high_severity_incidents,\n    \n    -- Category breakdown\n    COUNT(CASE WHEN category = 'payment' THEN 1 END) AS payment_incidents,\n    COUNT(CASE WHEN category = 'authentication' THEN 1 END) AS authentication_incidents,\n    COUNT(CASE WHEN category = 'performance' THEN 1 END) AS performance_incidents,\n    COUNT(CASE WHEN category = 'security' THEN 1 END) AS security_incidents,\n    \n    -- Source system breakdown\n    COUNT(CASE WHEN source_system = 'monitoring' THEN 1 END) AS monitoring_incidents,\n    COUNT(CASE WHEN source_system = 'customer_portal' THEN 1 END) AS customer_portal_incidents,\n    \n    -- Average resolution time for closed incidents (in hours)\n    AVG(\n        CASE \n            WHEN closed_at IS NOT NULL \n            THEN DATEDIFF('hour', created_at, closed_at)\n            ELSE NULL \n        END\n    ) AS avg_resolution_time_hours,\n    \n    -- Incidents with attachments\n    COUNT(CASE WHEN has_attachments = true THEN 1 END) AS incidents_with_attachments,\n    \n    -- Resolution rate percentage\n    ROUND(\n        (COUNT(CASE WHEN status IN ('resolved', 'closed') THEN 1 END)::DECIMAL / COUNT(*)) * 100, 2\n    ) AS resolution_rate_percentage\nFROM incident_management.gold_zone.incidents\nWHERE created_at >= DATEADD('year', -1, CURRENT_DATE())\nGROUP BY DATE_TRUNC('week', created_at)\nORDER BY week DESC", "relation_name": "incident_management.gold_zone.weekly_incident_trends", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-19T21:59:07.876807Z", "completed_at": "2025-11-19T21:59:07.892156Z"}, {"name": "execute", "started_at": "2025-11-19T21:59:07.892767Z", "completed_at": "2025-11-19T21:59:09.534986Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 1.6599111557006836, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c08107-0107-1236-0032-318705ad1f12"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.incident_management.incm360", "compiled": true, "compiled_code": "\n\nTABLES(\n  incidents as incident_management.gold_zone.incidents\n    PRIMARY KEY(incident_number)\n    COMMENT = 'Materialized incidents table with enriched data and calculated fields'\n\n  , active_incidents as incident_management.gold_zone.active_incidents\n    COMMENT = 'Active incidents requiring attention with SLA status and priority ordering'\n\n  , closed_incidents as incident_management.gold_zone.closed_incidents\n    COMMENT = 'Closed incidents with resolution metrics and performance insights'\n\n  , incident_attachments as incident_management.gold_zone.incident_attachments\n    COMMENT = 'Materialized incident attachments table'\n\n  , incident_comment_history as incident_management.gold_zone.incident_comment_history\n    COMMENT = 'Simplified incident comment history for tracking communication'\n\n  , weekly_incident_trends as incident_management.gold_zone.weekly_incident_trends\n    COMMENT = 'Weekly incident trends for the last 12 weeks'\n\n  , quaterly_review_metrics as incident_management.gold_zone.quaterly_review_metrics\n    COMMENT = 'Quarterly review metrics'\n\n  , users as incident_management.bronze_zone.users\n    COMMENT = 'Materialized users table with enriched data'\n\n)\n\nRELATIONSHIPS (\n    active_incidents_to_incidents AS\n      active_incidents (incident_number) REFERENCES incidents (incident_number)\n    , closed_incidents_to_incidents AS\n      closed_incidents (incident_number) REFERENCES incidents (incident_number)\n    , incident_attachments_to_incidents AS\n      incident_attachments (incident_number) REFERENCES incidents (incident_number)\n    , incident_comment_history_to_incidents AS\n      incident_comment_history (incident_number) REFERENCES incidents (incident_number)\n  )\n\n\nFACTS (\n    active_incidents.age_hours AS age_hours\n      COMMENT = 'Age of incident in hours'\n    , closed_incidents.total_resolution_hours AS total_resolution_hours\n      COMMENT = 'Total time from creation to closure in hours'\n    , closed_incidents.closed_year AS closed_year\n      COMMENT = 'Year when the incident was closed'\n    , closed_incidents.closed_quarter AS closed_quarter\n      COMMENT = 'Quarter when the incident was closed'\n\n    , weekly_incident_trends.total_incidents AS total_incidents\n      COMMENT = 'Total incidents created in the week'\n    , weekly_incident_trends.resolved_incidents AS resolved_incidents\n      COMMENT = 'Incidents resolved in the week'\n    , weekly_incident_trends.closed_incidents AS closed_incidents\n      COMMENT = 'Incidents closed in the week'\n    , weekly_incident_trends.open_incidents AS open_incidents\n      COMMENT = 'Incidents open in the week'\n    , weekly_incident_trends.critical_incidents AS critical_incidents\n      COMMENT = 'Incidents with critical priority'\n    , weekly_incident_trends.high_incidents AS high_incidents\n      COMMENT = 'Incidents with high priority'\n    , weekly_incident_trends.high_severity_incidents AS high_severity_incidents\n      COMMENT = 'Incidents with critical or high priority'\n    , weekly_incident_trends.payment_incidents AS payment_incidents\n      COMMENT = 'Payment category incidents'\n    , weekly_incident_trends.authentication_incidents AS authentication_incidents\n      COMMENT = 'Authentication category incidents'\n    , weekly_incident_trends.performance_incidents AS performance_incidents\n      COMMENT = 'Performance category incidents'\n    , weekly_incident_trends.security_incidents AS security_incidents\n      COMMENT = 'Security category incidents'\n    , weekly_incident_trends.monitoring_incidents AS monitoring_incidents\n      COMMENT = 'Incidents from monitoring source system'\n    , weekly_incident_trends.customer_portal_incidents AS customer_portal_incidents\n      COMMENT = 'Incidents from customer portal source system'\n    , weekly_incident_trends.avg_resolution_time_hours AS avg_resolution_time_hours\n      COMMENT = 'Average resolution time in hours'\n    , weekly_incident_trends.incidents_with_attachments AS incidents_with_attachments\n      COMMENT = 'Incidents that had attachments'\n    , weekly_incident_trends.resolution_rate_percentage AS resolution_rate_percentage\n      COMMENT = 'Share of resolved/closed incidents as a percentage'\n )\n\n DIMENSIONS (\n    incidents.incident_number AS incident_number\n    WITH SYNONYMS = ('incident', 'incident id')\n      COMMENT = 'Incident identifier'\n   , incidents.category AS category\n      WITH SYNONYMS = ('incident category', 'issue category', 'problem category', 'problem type')\n      COMMENT = 'Incident category'\n   , incidents.title AS title\n      WITH SYNONYMS = ('incident title', 'issue title', 'problem title', 'problem description')\n      COMMENT = 'Incident title'\n   , incidents.priority AS priority\n      COMMENT = 'Incident priority'\n   , incidents.status AS status\n      WITH SYNONYMS = ('incident status', 'issue status', 'problem status', 'problem status')\n      COMMENT = 'Incident status'\n   , incidents.assignee_id AS assignee_id\n      WITH SYNONYMS = ('assignee user id', 'assignee user id', 'assignee user id', 'assignee user id')\n      COMMENT = 'Assignee user id'\n   , incidents.reportee_id AS reportee_id\n      WITH SYNONYMS = ('reportee user id', 'reportee user id', 'reportee user id', 'reportee user id')\n      COMMENT = 'Reportee user id'\n   , incidents.created_at AS created_at\n      WITH SYNONYMS = ('creation timestamp', 'creation timestamp', 'creation timestamp', 'creation timestamp')\n      COMMENT = 'Creation timestamp'\n   , incidents.closed_at AS closed_at\n      WITH SYNONYMS = ('close timestamp', 'close timestamp', 'close timestamp', 'close timestamp')\n      COMMENT = 'Close timestamp'\n   , incidents.updated_at AS updated_at\n      WITH SYNONYMS = ('last update timestamp', 'last update timestamp', 'last update timestamp', 'last update timestamp')\n      COMMENT = 'Last update timestamp'\n   , incidents.source_system AS source_system\n      WITH SYNONYMS = ('source system', 'source system', 'source system', 'source system')\n      COMMENT = 'Source system for the incident'\n   ,incidents.external_source_id AS external_source_id\n      WITH SYNONYMS = ('external source identifier', 'external source identifier', 'external source identifier', 'external source identifier')\n      COMMENT = 'External source identifier'\n   , incidents.has_attachments AS has_attachments\n      WITH SYNONYMS = ('has attachments', 'has attachments', 'has attachments', 'has attachments')\n      COMMENT = 'Whether the incident has attachments'\n   , incidents.slack_message_id AS slack_message_id\n      WITH SYNONYMS = ('slack message id', 'slack message id', 'slack message id', 'slack message id')\n      COMMENT = 'Associated Slack message id'\n   , incidents.last_comment AS last_comment\n      WITH SYNONYMS = ('latest comment content', 'latest comment content', 'latest comment content', 'latest comment content')\n      COMMENT = 'Latest comment content'\n\n   , active_incidents.incident_number AS incident_number\n      COMMENT = 'Incident identifier'\n   , active_incidents.title AS title\n      COMMENT = 'Incident title'\n   , active_incidents.category AS category\n      COMMENT = 'Incident category'\n   , active_incidents.priority AS priority\n      COMMENT = 'Incident priority'\n   , active_incidents.status AS status\n      COMMENT = 'Incident status'\n   , active_incidents.assignee_id AS assignee_id\n      COMMENT = 'Assignee user id'\n   , active_incidents.assignee_name AS assignee_name\n      COMMENT = 'Assignee full name'\n   , active_incidents.reportee_id AS reportee_id\n      COMMENT = 'Reportee user id'\n   , active_incidents.reportee_name AS reportee_name\n      COMMENT = 'Reportee full name'\n   , active_incidents.created_at AS created_at\n      COMMENT = 'Creation timestamp'\n   , active_incidents.updated_at AS updated_at\n      COMMENT = 'Last update timestamp'\n   , active_incidents.source_system AS source_system\n      COMMENT = 'Source system for the incident'\n   , active_incidents.external_source_id AS external_source_id\n      COMMENT = 'External source identifier'\n   , active_incidents.has_attachments AS has_attachments\n      COMMENT = 'Whether the incident has attachments'\n\n   , closed_incidents.incident_number AS incident_number\n      COMMENT = 'Incident identifier'\n   , closed_incidents.title AS title\n      COMMENT = 'Incident title'\n   , closed_incidents.category AS category\n      COMMENT = 'Incident category'\n   , closed_incidents.priority AS priority\n      COMMENT = 'Incident priority'\n   , closed_incidents.status AS status\n      COMMENT = 'Incident status'\n   , closed_incidents.assignee_id AS assignee_id\n      COMMENT = 'Assignee user id'\n   , closed_incidents.reportee_id AS reportee_id\n      COMMENT = 'Reportee user id'\n   , closed_incidents.created_at AS created_at\n      COMMENT = 'Creation timestamp'\n   , closed_incidents.closed_at AS closed_at\n      COMMENT = 'Close timestamp'\n   , closed_incidents.updated_at AS updated_at\n      COMMENT = 'Last update timestamp'\n   , closed_incidents.source_system AS source_system\n      COMMENT = 'Source system for the incident'\n   , closed_incidents.external_source_id AS external_source_id\n      COMMENT = 'External source identifier'\n   , closed_incidents.has_attachments AS has_attachments\n      COMMENT = 'Whether the incident had attachments'\n   , closed_incidents.closed_month AS closed_month\n      COMMENT = 'Month when incident was closed'\n\n   , incident_attachments.id AS id\n      WITH SYNONYMS = ('attachment id', 'file id')\n      COMMENT = 'Attachment id'\n   , incident_attachments.incident_number AS incident_number\n      WITH SYNONYMS = ('incident', 'incident id')\n      COMMENT = 'Incident identifier'\n    , incident_attachments.attachment_file AS attachment_file\n      WITH SYNONYMS = ('stage file')\n      COMMENT = 'Stage file reference for the attachment'\n    , incident_attachments.uploaded_at AS uploaded_at\n      COMMENT = 'Attachment upload timestamp'\n\n   , incident_comment_history.id AS id\n      COMMENT = 'Comment id'\n   , incident_comment_history.incident_number AS incident_number\n      COMMENT = 'Incident identifier'\n   , incident_comment_history.author_id AS author_id\n      COMMENT = 'Comment author user id'\n   , incident_comment_history.content AS content\n      WITH SYNONYMS = ('comment', 'comment text')\n      COMMENT = 'Comment content'\n   , incident_comment_history.created_at AS created_at\n      COMMENT = 'Comment creation timestamp'\n   \n   , weekly_incident_trends.week AS week\n      COMMENT = 'Week bucket (date truncated to week)'\n\n   , quaterly_review_metrics.filename AS filename\n      COMMENT = 'Source document filename parsed from relative_path'\n   , quaterly_review_metrics.metric AS metric\n      WITH SYNONYMS = ('metric key', 'kpi')\n      COMMENT = 'Metric key extracted from the JSON response'\n   , quaterly_review_metrics.value AS value\n      WITH SYNONYMS = ('metric value', 'kpi value')\n      COMMENT = 'Metric value (string) extracted from the JSON response'\n   , quaterly_review_metrics.created_at AS created_at\n      COMMENT = 'Record creation timestamp'\n\n   , users.email AS email\n      WITH SYNONYMS = ('email', 'email address')\n      COMMENT = 'Primary email address'\n   , users.first_name AS first_name\n      WITH SYNONYMS = ('first name')\n      COMMENT = 'First name parsed from email user part'\n   , users.last_name AS last_name\n      WITH SYNONYMS = ('last name')\n      COMMENT = 'Last name parsed from email domain part'\n   , users.role AS role\n      COMMENT = 'User role'\n   , users.department AS department\n      COMMENT = 'User department'\n   , users.team AS team\n      COMMENT = 'User team'\n   , users.is_active AS is_active\n      COMMENT = 'Active flag'\n  )", "relation_name": "incident_management.semantic_views.incm360", "batch_results": null}], "elapsed_time": 53.55089020729065, "args": {"defer": false, "log_level_file": "debug", "version_check": true, "target_path": "/tmp/dbt/target/", "partial_parse": true, "write_json": true, "printer_width": 80, "print": true, "invocation_command": "dbt ", "log_format_file": "debug", "require_nested_cumulative_type_params": false, "empty": false, "cache_selected_only": false, "select": [], "target": "dev", "partial_parse_file_diff": true, "static_parser": true, "log_level": "info", "macro_debugging": false, "skip_nodes_if_on_run_start_fails": false, "populate_cache": true, "use_colors_file": true, "exclude": [], "log_path": "/tmp/dbt/logs", "warn_error_options": {"include": [], "exclude": []}, "vars": {}, "favor_state": false, "require_explicit_package_overrides_for_builtin_materializations": true, "send_anonymous_usage_stats": false, "require_batched_execution_for_custom_microbatch_strategy": false, "log_file_max_bytes": 10485760, "state_modified_compare_more_unrendered_values": false, "use_colors": true, "project_dir": "/tmp/dbt", "require_resource_names_without_spaces": false, "log_format": "default", "indirect_selection": "eager", "profiles_dir": "/tmp/dbt/", "require_yaml_configuration_for_mf_time_spines": false, "state_modified_compare_vars": false, "which": "run", "strict_mode": false, "introspect": true, "show_resource_report": false, "source_freshness_run_project_hooks": false, "quiet": false}}