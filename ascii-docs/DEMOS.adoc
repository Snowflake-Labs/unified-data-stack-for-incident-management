= Demo Vignettes & Usage Examples
:toc:
:toc-placement!:

This document provides practical examples and demonstrations of the Incident Management platform's key capabilities.

toc::[]

== Overview

This project demonstrates several key modern data platform capabilities through realistic incident management scenarios. Each vignette showcases a specific capability or integration pattern.


== Data Flow

=== Incident Lifecycle

. *Ingestion*: User posts incident message in Slack
   ** OpenFlow captures message metadata
   ** Attachments are stored and linked
   ** Raw data lands in `SLACK_MESSAGES` table

. *Qualification*: dbt processes raw messages
   ** Filters relevant incident messages
   ** Deduplicates records
   ** Creates qualified view for processing

. *Enrichment*: AI-powered classification
   ** Text analysis using Cortex AI functions
   ** Image classification for attachments
   ** Category and priority assignment

. *Structuring*: Incident record creation
   ** Generates unique incident IDs
   ** Links to reporters and assignees
   ** Creates comment and attachment records

. *Visualization*: Dashboard updates
   ** Real-time metrics calculation
   ** Active incident tracking
   ** Trend analysis



== OpenFlow-Based Slack Ingestion

=== Scenario

Real-time incident reporting through Slack with automatic data capture and processing.

=== Key Features Demonstrated

* Real-time data ingestion from external systems
* Unstructured data handling (text and images)
* Event-driven architecture
* Cloud-native integration patterns

=== Demo Flow

. *Report an Incident in Slack*
+
Post a message in your configured Slack channel:
+
----
Payment gateway is returning 500 errors
----

. *Attach Supporting Evidence*
+
Include a screenshot of the error page (use the sample images provided in `data/images/`):
+
   ** `payment_gateway_outage.jpeg`
   ** `invalid_credentials.jpeg`

. *Verify Ingestion*
+
Check that the message appears in Snowflake:
+
[source,sql]
----
SELECT * 
FROM SLACK_MESSAGES 
ORDER BY created_at DESC 
LIMIT 10;
----

. *Process the Data*
+
If Tasks are not set up, manually run the dbt Project:
+
[source,bash]
----
make run-dbt CONN=<your-connection-name>
----

. *View the Result*
+
Watch as the system creates a structured incident record with AI classification in the Streamlit dashboard.

=== What This Demonstrates

* Seamless integration between operational tools and data platforms
* Real-time data availability for analytics
* Support for multi-modal data (text + images)

== dbt Projects on Snowflake

=== Scenario 1: Remote Deployment and Execution

Working with dbt Projects directly in Snowflake without local dbt installation.

*Key Capabilities:*

* Deploy dbt projects using Snowflake CLI
* Execute dbt commands remotely
* Leverage Snowflake's compute for transformations

*Example Commands:*

[source,bash]
----
# Deploy dbt project to Snowflake
make deploy-dbt CONN=<your-connection-name>

# Execute dbt run
make run-dbt CONN=<your-connection-name>

# Execute with model selection
snow dbt run --select gold_zone.incidents
----

=== Scenario 2: Using Variables in dbt Projects

The project demonstrates variable usage in link:../src/incident_management/dbt_project.yml[`dbt_project.yml`].

*Example:*

[source,yaml]
----
vars:
  incident_categories:
    - 'payment gateway error'
    - 'login error'
    - 'database connectivity'
    - 'api timeout'
    - 'other'
----

These variables are referenced in models:

[source,sql]
----
-- In incidents.sql
ai_classify(text, {{ var('incident_categories') }})
----

=== Scenario 3: Scalable Data Transformation Pipeline

*Features:*

* Raw Slack data transformed into analytics-ready models
* Incremental processing for performance
* Data quality testing and documentation
* Complete data lineage tracking

*Key Models:*

. *Bronze Zone: Qualification Layer*
+
link:../src/incident_management/models/bronze_zone/v_qualify_slack_messages.sql[`v_qualify_slack_messages`]
+
   ** Filters relevant incident messages
   ** Removes duplicates using window functions
   ** Prepares clean data for transformation

. *Gold Zone: Incident Processing*
+
link:../src/incident_management/models/gold_zone/incidents.sql[`incidents`]
+
   ** AI-enhanced incident classification
   ** Multi-modal analysis (text + images)
   ** Automatic priority assignment

. *Gold Zone: Business Views*
+
link:../src/incident_management/models/gold_zone/active_incidents.sql[`active_incidents`]
+
   ** Real-time operational view
   ** Enriched with user information
   ** Calculated fields (age, SLA status)

=== What This Demonstrates

* Modern data engineering best practices
* Scalable transformation patterns
* Incremental processing strategies
* Data quality and testing frameworks

== AI/SQL Integration within dbt Models

=== Scenario

Intelligent incident classification and processing using embedded AI functions.

=== Unstructured Text Processing

==== Automatic Categorization

Classify incidents using natural language:

[source,sql]
----
-- From incidents.sql
ai_classify(
  sri.text, 
  ['payment gateway error', 'login error', 'other']
):labels[0] as category
----

*Example Input:*

----
"Users are reporting 500 errors when trying to complete checkout"
----

*AI Output:*

----
category: "payment gateway error"
----

==== Smart Incident Matching

Use AI to find related incidents:

[source,sql]
----
-- From incident_comment_history.sql
ai_filter(
  prompt(
    'The text category {0} is logically relatable to this record''s category {1}', 
    text_category, 
    roi.category
  )
)
----

*What This Does:*

* Matches new messages to existing incidents
* Uses semantic understanding, not keyword matching
* Automatically threads related comments

=== Image Processing

==== Multi-Modal Classification

Analyze both text and images for better classification:

[source,sql]
----
case 
  when sri.attachment_file is not null then 
    ai_classify(
      sri.attachment_file, 
      ['payment gateway error', 'login error', 'other']
    ):labels[0]
  else 
    ai_classify(
      sri.text, 
      ['payment gateway error', 'login error', 'other']
    ):labels[0]
end as category
----

*Example Scenario:*

. User posts vague message: "Something is broken"
. Attaches screenshot of payment error
. AI analyzes image and correctly classifies as "payment gateway error"

=== Priority Assignment

Automatically assign priority based on category:

[source,sql]
----
case 
  when category in ('payment gateway error', 'database connectivity') 
    then 'Critical'
  when category = 'login error' 
    then 'High'
  else 'Medium'
end as priority
----

=== What This Demonstrates

* AI-native data processing without external infrastructure
* Multi-modal AI analysis (text and images)
* Intelligent data enrichment
* No model training or maintenance required

[NOTE]
====
See complete implementation: link:../src/incident_management/models/gold_zone/incidents.sql[`incidents.sql`]
====

== Streamlit Dashboard

=== Scenario

Real-time operational dashboard for incident monitoring and management.

=== Key Features

==== 1. Real-Time Metrics

* Critical incident count
* High-priority incidents
* Active incidents
* Recently closed incidents
* Priority-based color coding

==== 2. Active Incidents Table

* Live view of open incidents
* Sortable and filterable
* Priority indicators
* Direct links to attachments

==== 3. Attachment Viewing

* In-app image viewing
* No need to download files
* Contextual evidence display

==== 4. Trend Analysis

* Weekly incident volumes
* Category distribution
* Resolution time trends
* Historical comparisons

=== Demo Flow

. *Open the Dashboard*
+
Navigate to your Streamlit app in Snowsight

. *View Metrics*
+
Top section shows key metrics with color coding

. *Explore Active Incidents*
+
Scroll through the active incidents table

. *View an Attachment*
+
Click on an incident with an attachment icon to view the image

. *Analyze Trends*
+
Review the trend charts to identify patterns

=== What This Demonstrates

* Real-time data visualization
* Interactive analytics
* Modern user experience
* Operational monitoring capabilities

== End-to-End Workflow Example

This example demonstrates the complete incident lifecycle from report to resolution.

=== Complete Incident Journey

==== 1. Report (Slack)

*User Posts:*

----
Our login page is showing 'Invalid credentials' for valid users
----

*Attachment:* Screenshot of login error (`invalid_credentials.jpeg`)

==== 2. Ingest (OpenFlow)

* OpenFlow captures message within seconds
* Stores text in `SLACK_MESSAGES` table
* Saves image file and metadata
* Triggers downstream processing

==== 3. Process (dbt)

*Qualification:*

[source,sql]
----
-- v_qualify_slack_messages.sql
-- Identifies this as an incident-related message
-- Removes any duplicate posts
----

*AI Classification:*

[source,sql]
----
-- incidents.sql
-- Text analysis: "Invalid credentials" â†’ login error
-- Image analysis: Confirms authentication issue
-- Priority assignment: HIGH
-- Generates incident ID: INC-2025-0042
----

*Result:*

----
incident_id: INC-2025-0042
title: "Invalid credentials for valid users"
category: "login error"
priority: "High"
status: "Open"
reporter: USLACK123
----

==== 4. Monitor (Streamlit)

* Dashboard updates with new critical incident
* Alert metrics increment
* Incident appears in active incidents table
* Attachment is viewable in-app

==== 5. Resolve (Team Action)

Team investigates and resolves the issue:

* Updates status to "In Progress" 
* Adds comments via Slack thread
* Resolves issue
* Updates status to "Closed"

==== 6. Analyze (System)

System automatically tracks:

* Time to resolution: 2 hours 15 minutes
* Category trending: Login errors increasing
* Resolution quality scoring
* Updates weekly trend reports

=== What This Demonstrates

* *Complete modern data stack* handling real-world operational scenarios
* *AI enhancement* at every step
* *Real-time visibility* into operations
* *Automated workflows* reducing manual effort
* *Data-driven insights* for continuous improvement

== Sample Test Scenarios

=== Test Scenario 1: Payment Gateway Outage

. *Message:* "Payment processing is completely down, customers can't check out"
. *Attachment:* `payment_gateway_outage.jpeg`
. *Expected Result:*
   ** Category: "payment gateway error"
   ** Priority: "Critical"
   ** Auto-assigned to on-call engineer

=== Test Scenario 2: Minor UI Issue

. *Message:* "The logo is slightly misaligned on mobile devices"
. *No Attachment*
. *Expected Result:*
   ** Category: "other"
   ** Priority: "Low"
   ** Added to backlog

=== Test Scenario 3: Database Connectivity

. *Message:* "Getting connection timeout errors to production database"
. *No Attachment*
. *Expected Result:*
   ** Category: "database connectivity"
   ** Priority: "Critical"
   ** Immediate escalation

== Running Your Own Tests

. *Post messages in your Slack channel* with various incident types
. *Run the dbt project* to process the messages
. *Check the dashboard* to see how incidents were classified
. *Verify AI classifications* match expected categories
. *Test attachment viewing* by uploading screenshots

== Next Steps

* Set up your own Slack channel following the link:setup.adoc[Setup Guide]
* Review the link:architecture.adoc[Architecture Documentation] to understand the data flow
* Explore the actual SQL in the model files to see implementation details
* Experiment with different incident scenarios

